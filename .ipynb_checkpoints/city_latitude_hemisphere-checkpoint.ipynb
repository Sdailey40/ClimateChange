{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import gkey\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import gmaps\n",
    "\n",
    "# Configure gmaps\n",
    "gmaps.configure(api_key=gkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url of national capitals for scraping\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_national_capitals_by_latitude'\n",
    "\n",
    "#temperaturate anamolies from https://data.giss.nasa.gov/gistemp/\n",
    "zonal_temp_anamolies = pd.read_csv('C:/Users/joelb/Documents/Github/ClimateChange/ZonAnn.Ts+dSST.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scrape html table from wikipediea\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "#grabs the 2nd table on the webpage\n",
    "city_by_hemisphere = tables[1]\n",
    "\n",
    "#give the table column names\n",
    "city_by_hemisphere.columns = ['City','Latitude','Country','Notes']\n",
    "\n",
    "#drops the first row that is just headers\n",
    "city_by_hemisphere = city_by_hemisphere.drop(0,axis=0)\n",
    "\n",
    "\n",
    "#converts the latitude column into numeric\n",
    "city_by_hemisphere['Latitude'] = city_by_hemisphere['Latitude'].str.replace('−','-')\n",
    "city_by_hemisphere['Latitude'] = pd.to_numeric(city_by_hemisphere['Latitude'])\n",
    "\n",
    "#if lat is negative its south, if positive its north\n",
    "city_by_hemisphere['Hemisphere'] = np.where(city_by_hemisphere['Latitude']<=0, 'south', 'north')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#determies what zone of the hemisphere the city is in\n",
    "city_by_hemisphere['zone'] = np.where(np.logical_and( \\\n",
    "                                    np.logical_and(city_by_hemisphere['Latitude']>0,city_by_hemisphere['Latitude']<=24), \\\n",
    "                                            city_by_hemisphere['Hemisphere'] == 'north'),'EQU-24N', \\\n",
    "                             np.where(np.logical_and( \\\n",
    "                                    np.logical_and(city_by_hemisphere['Latitude']>24,city_by_hemisphere['Latitude']<=44), \\\n",
    "                                            city_by_hemisphere['Hemisphere'] == 'north'),'24N-44N',\n",
    "                             np.where(np.logical_and( \\\n",
    "                                    np.logical_and(city_by_hemisphere['Latitude']>44,city_by_hemisphere['Latitude']<=64), \\\n",
    "                                            city_by_hemisphere['Hemisphere'] == 'north'),'44N-64N',\n",
    "                             np.where(np.logical_and( \\\n",
    "                                    np.logical_and(city_by_hemisphere['Latitude']>64,city_by_hemisphere['Latitude']<=90), \\\n",
    "                                            city_by_hemisphere['Hemisphere'] == 'north'),'64N-90N', \\\n",
    "                            np.where(np.logical_and( \\\n",
    "                                    np.logical_and(city_by_hemisphere['Latitude']<0,city_by_hemisphere['Latitude']>=-24), \\\n",
    "                                            city_by_hemisphere['Hemisphere'] == 'south'),'24S-EQU', \\\n",
    "                            np.where(np.logical_and( \\\n",
    "                                    np.logical_and(city_by_hemisphere['Latitude']<-24,city_by_hemisphere['Latitude']>=-44), \\\n",
    "                                            city_by_hemisphere['Hemisphere'] == 'south'),'44S-24S', \\\n",
    "                            np.where(np.logical_and( \\\n",
    "                                    np.logical_and(city_by_hemisphere['Latitude']<-44,city_by_hemisphere['Latitude']>=-64), \\\n",
    "                                            city_by_hemisphere['Hemisphere'] == 'south'),'64S-44S', \\\n",
    "                            np.where(np.logical_and( \\\n",
    "                                    np.logical_and(city_by_hemisphere['Latitude']<-64,city_by_hemisphere['Latitude']>=-90), \\\n",
    "                                            city_by_hemisphere['Hemisphere'] == 'south'),'64S-44S', \\\n",
    "                                     \"\"))))))))                                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get column headers for the year to be used later\n",
    "year_header = list(zonal_temp_anamolies['Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transpose the dataframe for merging\n",
    "zonal_temp_anamolies = zonal_temp_anamolies.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#merge the city capitals with the zonal temperature data\n",
    "climate_df =  city_by_hemisphere.merge(zonal_temp_anamolies, how='left', left_on='zone', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns to the appropriate year\n",
    "climate_df.rename(columns=dict(zip(climate_df.columns[6:],year_header)),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop a notes column that is not needed\n",
    "climate_df = climate_df.drop('Notes',axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#sums temperature anomalies over a period of years.  will be the layers on the leaflet map\n",
    "climate_df['rng_1880_1910'] = climate_df.iloc[:, 5:36].sum(axis='columns')\n",
    "climate_df['rng_1911_1940'] = climate_df.iloc[:, 36:66].sum(axis='columns')\n",
    "climate_df['rng_1941_1970'] = climate_df.iloc[:, 66:96].sum(axis='columns')\n",
    "climate_df['rng_1971_2000'] = climate_df.iloc[:, 96:126].sum(axis='columns')\n",
    "climate_df['rng_2001_2017'] = climate_df.iloc[:, 126:143].sum(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# climate_df.to_excel('C:/Users/joelb/Documents/Github/ClimateChange/test.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create lat and lgn fields for google maps geocode api\n",
    "climate_df[\"Lat\"] = \"\"\n",
    "climate_df[\"Lng\"] = \"\"\n",
    "\n",
    "#set parameters to my gkey\n",
    "params = {\"key\": gkey}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num records processed1\n",
      "num records processed2\n",
      "num records processed3\n",
      "num records processed4\n",
      "num records processed5\n",
      "num records processed6\n",
      "num records processed7\n",
      "num records processed8\n",
      "num records processed9\n",
      "num records processed10\n",
      "num records processed11\n",
      "num records processed12\n",
      "num records processed13\n",
      "num records processed14\n",
      "num records processed15\n",
      "num records processed16\n",
      "num records processed17\n",
      "num records processed18\n",
      "num records processed19\n",
      "num records processed20\n",
      "num records processed21\n",
      "num records processed22\n",
      "num records processed23\n",
      "num records processed24\n",
      "num records processed25\n",
      "num records processed26\n",
      "num records processed27\n",
      "num records processed28\n",
      "num records processed29\n",
      "num records processed30\n",
      "num records processed31\n",
      "num records processed32\n",
      "num records processed33\n",
      "num records processed34\n",
      "num records processed35\n",
      "num records processed36\n",
      "num records processed37\n",
      "num records processed38\n",
      "num records processed39\n",
      "num records processed40\n",
      "num records processed41\n",
      "num records processed42\n",
      "num records processed43\n",
      "num records processed44\n",
      "num records processed45\n",
      "num records processed46\n",
      "num records processed47\n",
      "num records processed48\n",
      "num records processed49\n",
      "num records processed50\n",
      "num records processed51\n",
      "num records processed52\n",
      "num records processed53\n",
      "num records processed54\n",
      "num records processed55\n",
      "num records processed56\n",
      "num records processed57\n",
      "num records processed58\n",
      "num records processed59\n",
      "num records processed60\n",
      "num records processed61\n",
      "num records processed62\n",
      "num records processed63\n",
      "num records processed64\n",
      "num records processed65\n",
      "num records processed66\n",
      "num records processed67\n",
      "num records processed68\n",
      "num records processed69\n",
      "num records processed70\n",
      "num records processed71\n",
      "num records processed72\n",
      "num records processed73\n",
      "num records processed74\n",
      "num records processed75\n",
      "num records processed76\n",
      "num records processed77\n",
      "num records processed78\n",
      "num records processed79\n",
      "num records processed80\n",
      "num records processed81\n",
      "num records processed82\n",
      "num records processed83\n",
      "num records processed84\n",
      "num records processed85\n",
      "num records processed86\n",
      "num records processed87\n",
      "num records processed88\n",
      "num records processed89\n",
      "num records processed90\n",
      "num records processed91\n",
      "num records processed92\n",
      "num records processed93\n",
      "num records processed94\n",
      "num records processed95\n",
      "num records processed96\n",
      "num records processed97\n",
      "num records processed98\n",
      "num records processed99\n",
      "num records processed100\n",
      "num records processed101\n",
      "num records processed102\n",
      "num records processed103\n",
      "num records processed104\n",
      "num records processed105\n",
      "num records processed106\n",
      "num records processed107\n",
      "num records processed108\n",
      "num records processed109\n",
      "num records processed110\n",
      "num records processed111\n",
      "num records processed112\n",
      "num records processed113\n",
      "num records processed114\n",
      "num records processed115\n",
      "num records processed116\n",
      "num records processed117\n",
      "num records processed118\n",
      "num records processed119\n",
      "num records processed120\n",
      "num records processed121\n",
      "num records processed122\n",
      "num records processed123\n",
      "num records processed124\n",
      "num records processed125\n",
      "num records processed126\n",
      "num records processed127\n",
      "num records processed128\n",
      "num records processed129\n",
      "num records processed130\n",
      "num records processed131\n",
      "num records processed132\n",
      "num records processed133\n",
      "num records processed134\n",
      "num records processed135\n",
      "num records processed136\n",
      "num records processed137\n",
      "num records processed138\n",
      "num records processed139\n",
      "num records processed140\n",
      "num records processed141\n",
      "num records processed142\n",
      "num records processed143\n",
      "num records processed144\n",
      "num records processed145\n",
      "num records processed146\n",
      "num records processed147\n",
      "num records processed148\n",
      "num records processed149\n",
      "num records processed150\n",
      "num records processed151\n",
      "num records processed152\n",
      "num records processed153\n",
      "num records processed154\n",
      "num records processed155\n",
      "num records processed156\n",
      "num records processed157\n",
      "num records processed158\n",
      "num records processed159\n",
      "num records processed160\n",
      "num records processed161\n",
      "num records processed162\n",
      "num records processed163\n",
      "num records processed164\n",
      "num records processed165\n",
      "num records processed166\n",
      "num records processed167\n",
      "num records processed168\n",
      "num records processed169\n",
      "num records processed170\n",
      "num records processed171\n",
      "num records processed172\n",
      "num records processed173\n",
      "num records processed174\n",
      "num records processed175\n",
      "num records processed176\n",
      "num records processed177\n",
      "num records processed178\n",
      "num records processed179\n",
      "num records processed180\n",
      "num records processed181\n",
      "num records processed182\n",
      "num records processed183\n",
      "num records processed184\n",
      "num records processed185\n",
      "num records processed186\n",
      "num records processed187\n",
      "num records processed188\n",
      "num records processed189\n",
      "num records processed190\n",
      "num records processed191\n",
      "num records processed192\n",
      "num records processed193\n",
      "num records processed194\n",
      "num records processed195\n",
      "num records processed196\n",
      "num records processed197\n",
      "num records processed198\n",
      "num records processed199\n",
      "num records processed200\n",
      "num records processed201\n",
      "num records processed202\n",
      "num records processed203\n",
      "num records processed204\n",
      "num records processed205\n",
      "num records processed206\n",
      "num records processed207\n",
      "num records processed208\n",
      "num records processed209\n",
      "didnt copy street: city: Sucre (constitutional)La Paz (administrative)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'street' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-c911e221e193>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mclimate_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Lat\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcities_lat_lng\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"results\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"geometry\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"location\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lat\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mclimate_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Lng\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcities_lat_lng\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"results\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"geometry\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"location\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lng\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-c911e221e193>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"didnt copy street: \"\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[1;34m\"city: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcity\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mbad_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstreet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'street' is not defined"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "bad_list = []\n",
    "\n",
    "for index, row in climate_df.iterrows():\n",
    "    base_url = \"https://maps.googleapis.com/maps/api/geocode/json\"\n",
    "\n",
    "    city = row['City']\n",
    "    country = row['Country']\n",
    "\n",
    "    # update address key value\n",
    "    params['address'] = f\"{city},{country}\"\n",
    "\n",
    "    # make request, print url\n",
    "    cities_lat_lng = requests.get(base_url, params=params)\n",
    "    \n",
    "    # convert to json\n",
    "    cities_lat_lng = cities_lat_lng.json()\n",
    "    \n",
    "    try:\n",
    "\n",
    "        climate_df.loc[index, \"Lat\"] = cities_lat_lng[\"results\"][0][\"geometry\"][\"location\"][\"lat\"]\n",
    "        climate_df.loc[index, \"Lng\"] = cities_lat_lng[\"results\"][0][\"geometry\"][\"location\"][\"lng\"]\n",
    "\n",
    "        count +=1\n",
    "        print(\"num records processed\" + str(count))\n",
    "    except:\n",
    "        print(\"didnt copy street: \" +  \"city: \" + city )\n",
    "        bad_list.append(city)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop original lat field so it does not conflict with google lat field\n",
    "climate_df = climate_df.drop('Latitude',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Hemisphere</th>\n",
       "      <th>zone</th>\n",
       "      <th>1880</th>\n",
       "      <th>1881</th>\n",
       "      <th>1882</th>\n",
       "      <th>1883</th>\n",
       "      <th>1884</th>\n",
       "      <th>1885</th>\n",
       "      <th>1886</th>\n",
       "      <th>...</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>rng_1880_1910</th>\n",
       "      <th>rng_1911_1940</th>\n",
       "      <th>rng_1941_1970</th>\n",
       "      <th>rng_1971_2000</th>\n",
       "      <th>rng_2001_2017</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lng</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abu Dhabi</th>\n",
       "      <td>United Arab Emirates</td>\n",
       "      <td>north</td>\n",
       "      <td>24N-44N</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.02</td>\n",
       "      <td>-8.9</td>\n",
       "      <td>-5.35</td>\n",
       "      <td>1.64</td>\n",
       "      <td>3.36</td>\n",
       "      <td>12.11</td>\n",
       "      <td>24.4539</td>\n",
       "      <td>54.3773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Country Hemisphere     zone  1880  1881  1882  1883  \\\n",
       "City                                                                          \n",
       "Abu Dhabi  United Arab Emirates      north  24N-44N -0.26 -0.15 -0.09 -0.22   \n",
       "\n",
       "           1884  1885  1886   ...     2015  2016  2017  rng_1880_1910  \\\n",
       "City                          ...                                       \n",
       "Abu Dhabi -0.41 -0.42  -0.4   ...      1.0  1.06  1.02           -8.9   \n",
       "\n",
       "           rng_1911_1940  rng_1941_1970  rng_1971_2000  rng_2001_2017  \\\n",
       "City                                                                    \n",
       "Abu Dhabi          -5.35           1.64           3.36          12.11   \n",
       "\n",
       "               Lat      Lng  \n",
       "City                         \n",
       "Abu Dhabi  24.4539  54.3773  \n",
       "\n",
       "[1 rows x 148 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abu Dhabi'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_dict = {'City': climate_df['City'],\n",
    "               'Country':climate_df['Country'],\n",
    "               'Lat':climate_df['Lat'],\n",
    "               'Lng':climate_df['Lng'],\n",
    "                'rng_1880_1910': climate_df['rng_1880_1910'],\n",
    "                'rng_1911_1940':climate_df['rng_1911_1940'],\n",
    "                'rng_1941_1970':climate_df['rng_1941_1970'],\n",
    "                'rng_1971_2000':climate_df['rng_1971_2000'],\n",
    "                'rng_2001_2017':climate_df['rng_2001_2017']\n",
    "               }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "City\n",
       "Abu Dhabi    United Arab Emirates\n",
       "Name: Country, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-240bec9b27ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'columns'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Lat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
